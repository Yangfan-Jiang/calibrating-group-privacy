{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learning with Group Privacy\n",
    "from MLModel import *\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scattering, K, (h, w) = get_scatter_transform(dataset=\"cifar10\")\n",
    "scattering.to(device)\n",
    "\n",
    "def get_scattered_feature(dataset):\n",
    "    scatters = []\n",
    "    targets = []\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=256, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "    \n",
    "    for (data, target) in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if scattering is not None:\n",
    "            data = scattering(data)\n",
    "        scatters.append(data)\n",
    "        targets.append(target)\n",
    "\n",
    "    scatters = torch.cat(scatters, axis=0)\n",
    "    targets = torch.cat(targets, axis=0)\n",
    "\n",
    "    data = torch.utils.data.TensorDataset(scatters, targets)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_cifar10():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_transforms = [transforms.ToTensor(), normalize,]\n",
    "\n",
    "    train = datasets.CIFAR10(root=\"~/data/\", train=True,\n",
    "                                 transform=transforms.Compose(train_transforms),\n",
    "                                 download=True)\n",
    "\n",
    "    test = datasets.CIFAR10(root=\"~/data/\", train=False,\n",
    "                                transform=transforms.Compose(\n",
    "                                    [transforms.ToTensor(), normalize]\n",
    "                                ))\n",
    "    \n",
    "    # get scattered features\n",
    "    train = get_scattered_feature(train)\n",
    "    test = get_scattered_feature(test)\n",
    "    \n",
    "    train_data = train[:][0].squeeze().cpu().float()\n",
    "    train_label = train[:][1].cpu()\n",
    "    \n",
    "    test_data = test[:][0].squeeze().cpu().float()\n",
    "    test_label = test[:][1].cpu()\n",
    "\n",
    "    dataset = [(train_data, train_label), (test_data, test_label)]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = load_cifar10()\n",
    "\n",
    "train_data = torch.tensor(d[0][0]).to(device)\n",
    "train_label = torch.tensor(d[0][1]).to(device)\n",
    "\n",
    "test_data = torch.tensor(d[1][0]).to(device)\n",
    "test_label = torch.tensor(d[1][1]).to(device)\n",
    "\n",
    "data_size = len(train_label)\n",
    "print(\"#. training records=\",data_size)\n",
    "\n",
    "print(\"shape of training records: \",d[0][0].shape)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FL model parameters.\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lr = 1.5\n",
    "iters = 500\n",
    "\n",
    "configs = {\n",
    "    'output_size': 10,\n",
    "    'data_size': data_size,\n",
    "    'model': 'scatter',\n",
    "    'data': d,\n",
    "    'lr': lr,\n",
    "    'E': iters,\n",
    "    'delta': 1e-5,\n",
    "    'q': 0.1,\n",
    "    'clip': 0.1,\n",
    "    'batch_size': 128,\n",
    "    'device': device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_acc(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        tot_sample = len(test_data)\n",
    "        #for i in range(len(test_data)):\n",
    "\n",
    "        t_pred_y = model(test_data)\n",
    "        _, predicted = torch.max(t_pred_y, 1)\n",
    "        correct += (predicted == test_label).sum().item()\n",
    "\n",
    "        acc = correct / tot_sample\n",
    "    model.train()\n",
    "    return acc\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=configs['lr'], momentum=0.9)\n",
    "    # optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    start_time = time.time()\n",
    "    for e in range(configs['E']):\n",
    "        model.train()\n",
    "        # randomly select q fraction samples from dataset by poisson sampling\n",
    "        idx = np.where(np.random.rand(len(torch_train[:][0])) < configs['q'])[0]\n",
    "\n",
    "        sampled_dataset = TensorDataset(torch_train[idx][0], torch_train[idx][1])\n",
    "        sample_data_loader = DataLoader(\n",
    "            dataset=sampled_dataset,\n",
    "            batch_size=configs['batch_size'],\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        clipped_grads = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "        for batch_x, batch_y in sample_data_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            pred_y = model(batch_x.float())\n",
    "            loss = criterion(pred_y, batch_y.long())\n",
    "\n",
    "            # bound l2 sensitivity (gradient clipping)\n",
    "            # clip each of the gradient in subset\n",
    "            for i in range(loss.size()[0]):\n",
    "                loss[i].backward(retain_graph=True)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=configs['clip'])\n",
    "                for name, param in model.named_parameters():\n",
    "                    clipped_grads[name] += param.grad \n",
    "                model.zero_grad()\n",
    "\n",
    "        # add Gaussian noise\n",
    "        for name, param in model.named_parameters():\n",
    "            clipped_grads[name] += gaussian_noise(clipped_grads[name].shape, configs['clip'], configs['sigma'], device=device)\n",
    "\n",
    "        # scale back\n",
    "        for name, param in model.named_parameters():\n",
    "            clipped_grads[name] /= (configs['data_size']*configs['q'])\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            param.grad = clipped_grads[name]\n",
    "\n",
    "        # update local model\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (e+1)%2 == 0:\n",
    "            acc = test_acc(model)\n",
    "            print(\"iters = {:d}, acc = {:.4f}\".format(e+1, acc), \" Time taken: %.2fs\" % (time.time() - start_time))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying group size $m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "noise scale is calibrated using binary search,\n",
    "see 'calibrate_sgm_noise.ipynb' file\n",
    "\"\"\"\n",
    "m_list = [8, 16, 32, 64]\n",
    "m_list_ours = [8, 16, 24, 32, 40, 48, 56, 64]\n",
    "\n",
    "noise_rdp= [38.10931396484375, 93.24703979492188, 228.32774353027344, 559.2231292724609]\n",
    "noise_ours= [30.653938055038452, 52.265591621398926, 73.35555791854858, 94.27658557891846, 115.12147188186646, 135.92471837997437, 156.70357584953308, 177.46637225151062]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Naive RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sigma in enumerate(noise_rdp):\n",
    "    print(\"sigma =\",sigma)\n",
    "    configs['sigma'] = sigma\n",
    "    acc_list = []\n",
    "    for _ in range(5):\n",
    "        model = ScatterLinear(243, (8, 8), input_norm=\"GroupNorm\", num_groups=27).to(device)\n",
    "        torch_train = TensorDataset(torch.tensor(train_data), torch.tensor(train_label))\n",
    "        acc = train()\n",
    "        acc_list.append(acc)\n",
    "    print(\"m = {:d}, avg acc = {:.4f}\".format(m_list[i], np.mean(acc_list)) )\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sigma in noise_ours:\n",
    "    print(\"sigma =\",sigma)\n",
    "    configs['sigma'] = sigma\n",
    "    acc_list = []\n",
    "    for _ in range(5):\n",
    "        model = ScatterLinear(243, (8, 8), input_norm=\"GroupNorm\", num_groups=27).to(device)\n",
    "        torch_train = TensorDataset(torch.tensor(train_data), torch.tensor(train_label))\n",
    "        acc = train()\n",
    "        acc_list.append(acc)\n",
    "    print(\"avg acc =\", np.mean(acc_list))\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vary privacy parameter $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "noise scale is calibrated using binary search,\n",
    "see 'calibrate_sgm_noise.ipynb' file\n",
    "\"\"\"\n",
    "# m = 32\n",
    "eps_list = [8, 7, 6, 5, 4, 3, 2]\n",
    "\n",
    "noise_rdp= [62.96098327636719, 70.53829956054688, 80.5775146484375, 94.09147644042969, 114.18656921386719, 147.5915069580078, 211.9739990234375]\n",
    "noise_ours= [29.204277992248535, 32.63718247413635, 37.39244818687439, 43.51409435272217, 52.82178044319153, 68.23326706886292, 97.94802665710449]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive RDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in noise_rdp:\n",
    "    print(\"sigma =\",sigma)\n",
    "    configs['sigma'] = sigma\n",
    "    acc_list = []\n",
    "    for _ in range(5):\n",
    "        model = ScatterLinear(243, (8, 8), input_norm=\"GroupNorm\", num_groups=27).to(device)\n",
    "        torch_train = TensorDataset(torch.tensor(train_data), torch.tensor(train_label))\n",
    "        acc = train()\n",
    "        acc_list.append(acc)\n",
    "    print(\"avg acc =\", np.mean(acc_list))\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sigma in noise_ours:\n",
    "    print(\"sigma =\",sigma)\n",
    "    configs['sigma'] = sigma\n",
    "    acc_list = []\n",
    "    for _ in range(5):\n",
    "        model = ScatterLinear(243, (8, 8), input_norm=\"GroupNorm\", num_groups=27).to(device)\n",
    "        torch_train = TensorDataset(torch.tensor(train_data), torch.tensor(train_label))\n",
    "        acc = train()\n",
    "        acc_list.append(acc)\n",
    "    print(\"avg acc =\", np.mean(acc_list))\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
